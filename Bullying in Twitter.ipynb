{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pylab inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "import folium\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import cross_validation\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter path for training dataset: database.csv\n",
      "Enter path for new dataset: tweets May 26.csv\n"
     ]
    }
   ],
   "source": [
    "file = input('Enter path for training dataset: ')\n",
    "train_data = pd.read_csv(file,encoding='ISO-8859-1')\n",
    "train_data\n",
    "file = input('Enter path for new dataset: ')\n",
    "new_data = pd.read_csv(file, encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15  6]\n",
      " [ 4 54]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      Bully       0.79      0.71      0.75        21\n",
      "  Not bully       0.90      0.93      0.92        58\n",
      "\n",
      "avg / total       0.87      0.87      0.87        79\n",
      "\n",
      "Accuracy score: 0.873417721519\n"
     ]
    }
   ],
   "source": [
    "X = train_data\n",
    "y = train_data['classification 2']\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1)\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.1, random_state=1)\n",
    "\n",
    "vect = CountVectorizer(ngram_range=(1,5), max_df=0.99)\n",
    "\n",
    "X_train_dtm = vect.fit_transform(X_train.text)\n",
    "X_test_dtm = vect.transform(X_test.text)\n",
    "\n",
    "X_tokens = vect.get_feature_names()\n",
    "# print (X_tokens[2040:])\n",
    "\n",
    "vect = CountVectorizer(stop_words = 'english', ngram_range=(1,5), max_df=0.99)\n",
    "\n",
    "X_train_dtm = vect.fit_transform(X_train.text)\n",
    "X_test_dtm = vect.transform(X_test.text)\n",
    "\n",
    "nb = MultinomialNB(alpha=0.001)\n",
    "nb = nb.fit(X_train_dtm, y_train)\n",
    "\n",
    "y_predicted = nb.predict(X_test_dtm)\n",
    "\n",
    "print(confusion_matrix(y_test, y_predicted))\n",
    "print(classification_report(y_test, y_predicted))\n",
    "print('Accuracy score: '+str(metrics.accuracy_score(y_test, y_predicted)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>taas taas nagd ni tolerance ka roommates ko sa...</td>\n",
       "      <td>Not bully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30233</th>\n",
       "      <td>Team @MercadoJen all d way &lt;ed&gt;&lt;U+00A0&gt;&lt;U+00BD...</td>\n",
       "      <td>Not bully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>I scream for ice cream and coffee &lt;ed&gt;&lt;U+00A0&gt;...</td>\n",
       "      <td>Not bully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126487</th>\n",
       "      <td>18 sec then 12 sec. Another 30sec kiss. Grabe ...</td>\n",
       "      <td>Not bully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129871</th>\n",
       "      <td>masakit lang talaga sa heart ko di ko na kaya ...</td>\n",
       "      <td>Not bully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22043</th>\n",
       "      <td>SG is real na. Booking nalang tsaka confirmation</td>\n",
       "      <td>Not bully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114607</th>\n",
       "      <td>Sleeping over for the night. (@ EM's Barrio So...</td>\n",
       "      <td>Not bully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78072</th>\n",
       "      <td>anyone knows how to make a mood board? i need ...</td>\n",
       "      <td>Not bully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100300</th>\n",
       "      <td>@jaypriet0 I love it, feels so cool.</td>\n",
       "      <td>Not bully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41838</th>\n",
       "      <td>#ALDUBxDTBYFinale road to 600k na dotdot pa</td>\n",
       "      <td>Not bully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88340</th>\n",
       "      <td>pagtripan ke nga ivan HAHAHAHAHAHAHHAHAHAHAHAH...</td>\n",
       "      <td>Not bully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65651</th>\n",
       "      <td>Jgh. Kapuya woy</td>\n",
       "      <td>Not bully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110081</th>\n",
       "      <td>OA ni ya si Maggie ho. Wala man ya naging sila...</td>\n",
       "      <td>Not bully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119927</th>\n",
       "      <td>\"I don't want to be with anyone except you. I ...</td>\n",
       "      <td>Not bully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35507</th>\n",
       "      <td>GRABE WALANG SUPPORT!</td>\n",
       "      <td>Not bully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114028</th>\n",
       "      <td>@itsmemarielle28 @iamJulianT hahaha oo yun nal...</td>\n",
       "      <td>Not bully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119889</th>\n",
       "      <td>Mom knows me well hahahahaha</td>\n",
       "      <td>Not bully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114377</th>\n",
       "      <td>@clnsrmnto hahaha gulo mo celene! sa monday?</td>\n",
       "      <td>Not bully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96357</th>\n",
       "      <td>Pagka june bawal na lumabas&lt;ed&gt;&lt;U+00A0&gt;&lt;U+00BD...</td>\n",
       "      <td>Bully</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90409</th>\n",
       "      <td>@AmalinaBuhtamam Wau hebat jiran sa pling extr...</td>\n",
       "      <td>Not bully</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Input Prediction\n",
       "158     taas taas nagd ni tolerance ka roommates ko sa...  Not bully\n",
       "30233   Team @MercadoJen all d way <ed><U+00A0><U+00BD...  Not bully\n",
       "1099    I scream for ice cream and coffee <ed><U+00A0>...  Not bully\n",
       "126487  18 sec then 12 sec. Another 30sec kiss. Grabe ...  Not bully\n",
       "129871  masakit lang talaga sa heart ko di ko na kaya ...  Not bully\n",
       "22043    SG is real na. Booking nalang tsaka confirmation  Not bully\n",
       "114607  Sleeping over for the night. (@ EM's Barrio So...  Not bully\n",
       "78072   anyone knows how to make a mood board? i need ...  Not bully\n",
       "100300               @jaypriet0 I love it, feels so cool.  Not bully\n",
       "41838         #ALDUBxDTBYFinale road to 600k na dotdot pa  Not bully\n",
       "88340   pagtripan ke nga ivan HAHAHAHAHAHAHHAHAHAHAHAH...  Not bully\n",
       "65651                                     Jgh. Kapuya woy  Not bully\n",
       "110081  OA ni ya si Maggie ho. Wala man ya naging sila...  Not bully\n",
       "119927  \"I don't want to be with anyone except you. I ...  Not bully\n",
       "35507                               GRABE WALANG SUPPORT!  Not bully\n",
       "114028  @itsmemarielle28 @iamJulianT hahaha oo yun nal...  Not bully\n",
       "119889                       Mom knows me well hahahahaha  Not bully\n",
       "114377       @clnsrmnto hahaha gulo mo celene! sa monday?  Not bully\n",
       "96357   Pagka june bawal na lumabas<ed><U+00A0><U+00BD...      Bully\n",
       "90409   @AmalinaBuhtamam Wau hebat jiran sa pling extr...  Not bully"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_dtm = vect.transform(new_data['text'])\n",
    "y_predicted = nb.predict(X_test_dtm)\n",
    "\n",
    "input_text = pd.DataFrame(new_data.text.tolist())\n",
    "prediction = pd.DataFrame(y_predicted)\n",
    "table = pd.concat([input_text,prediction],axis=1)\n",
    "table.columns = ['Input','Prediction']\n",
    "table.to_csv('predicted_'+file)\n",
    "table.sample(n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokens Influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>Bully</th>\n",
       "      <th>Not bully</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4107</th>\n",
       "      <td>ed</td>\n",
       "      <td>134.0</td>\n",
       "      <td>688.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4165</th>\n",
       "      <td>ed ed</td>\n",
       "      <td>94.0</td>\n",
       "      <td>494.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8295</th>\n",
       "      <td>ka</td>\n",
       "      <td>79.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12128</th>\n",
       "      <td>mo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4211</th>\n",
       "      <td>ed ed ed</td>\n",
       "      <td>54.0</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5464</th>\n",
       "      <td>gago</td>\n",
       "      <td>51.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19200</th>\n",
       "      <td>tangina</td>\n",
       "      <td>43.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4220</th>\n",
       "      <td>ed ed ed ed</td>\n",
       "      <td>39.0</td>\n",
       "      <td>225.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2803</th>\n",
       "      <td>co</td>\n",
       "      <td>38.0</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7118</th>\n",
       "      <td>https co</td>\n",
       "      <td>38.0</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7117</th>\n",
       "      <td>https</td>\n",
       "      <td>38.0</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12765</th>\n",
       "      <td>na</td>\n",
       "      <td>36.0</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9508</th>\n",
       "      <td>ko</td>\n",
       "      <td>27.0</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16723</th>\n",
       "      <td>putangina</td>\n",
       "      <td>26.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11880</th>\n",
       "      <td>mga</td>\n",
       "      <td>25.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17188</th>\n",
       "      <td>sa</td>\n",
       "      <td>25.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4225</th>\n",
       "      <td>ed ed ed ed ed</td>\n",
       "      <td>24.0</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13998</th>\n",
       "      <td>ng</td>\n",
       "      <td>23.0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>ang</td>\n",
       "      <td>21.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>ako</td>\n",
       "      <td>18.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2217</th>\n",
       "      <td>bobo</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19355</th>\n",
       "      <td>tangina mo</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21958</th>\n",
       "      <td>you</td>\n",
       "      <td>15.0</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19134</th>\n",
       "      <td>tanga</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5564</th>\n",
       "      <td>gago ka</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10198</th>\n",
       "      <td>lang</td>\n",
       "      <td>13.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20332</th>\n",
       "      <td>to</td>\n",
       "      <td>13.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470</th>\n",
       "      <td>ba</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16674</th>\n",
       "      <td>puta</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3551</th>\n",
       "      <td>di</td>\n",
       "      <td>12.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15251</th>\n",
       "      <td>pa</td>\n",
       "      <td>11.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22200</th>\n",
       "      <td>yung</td>\n",
       "      <td>11.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4625</th>\n",
       "      <td>eh</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16246</th>\n",
       "      <td>po</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18999</th>\n",
       "      <td>talaga</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13588</th>\n",
       "      <td>naman</td>\n",
       "      <td>9.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9924</th>\n",
       "      <td>kung</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5365</th>\n",
       "      <td>fuck</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20867</th>\n",
       "      <td>ulol</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9210</th>\n",
       "      <td>kaya</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9254</th>\n",
       "      <td>kayo</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14717</th>\n",
       "      <td>nyo</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14454</th>\n",
       "      <td>niyo</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18038</th>\n",
       "      <td>si</td>\n",
       "      <td>7.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11697</th>\n",
       "      <td>me</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16798</th>\n",
       "      <td>putangina mo</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8312</th>\n",
       "      <td>ka ba</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15615</th>\n",
       "      <td>pang</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5373</th>\n",
       "      <td>fuck you</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6965</th>\n",
       "      <td>hindi</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tokens  Bully  Not bully\n",
       "4107               ed  134.0      688.0\n",
       "4165            ed ed   94.0      494.0\n",
       "8295               ka   79.0       53.0\n",
       "12128              mo   70.0       35.0\n",
       "4211         ed ed ed   54.0      300.0\n",
       "5464             gago   51.0       53.0\n",
       "19200         tangina   43.0       68.0\n",
       "4220      ed ed ed ed   39.0      225.0\n",
       "2803               co   38.0      119.0\n",
       "7118         https co   38.0      119.0\n",
       "7117            https   38.0      119.0\n",
       "12765              na   36.0      107.0\n",
       "9508               ko   27.0       86.0\n",
       "16723       putangina   26.0       12.0\n",
       "11880             mga   25.0       15.0\n",
       "17188              sa   25.0       58.0\n",
       "4225   ed ed ed ed ed   24.0      150.0\n",
       "13998              ng   23.0       37.0\n",
       "756               ang   21.0       42.0\n",
       "224               ako   18.0       52.0\n",
       "2217             bobo   16.0        2.0\n",
       "19355      tangina mo   15.0        6.0\n",
       "21958             you   15.0       42.0\n",
       "19134           tanga   14.0       11.0\n",
       "5564          gago ka   14.0        4.0\n",
       "10198            lang   13.0       38.0\n",
       "20332              to   13.0       38.0\n",
       "1470               ba   13.0       13.0\n",
       "16674            puta   12.0        9.0\n",
       "3551               di   12.0       22.0\n",
       "15251              pa   11.0       30.0\n",
       "22200            yung   11.0       33.0\n",
       "4625               eh   11.0       11.0\n",
       "16246              po   11.0       10.0\n",
       "18999          talaga   10.0       20.0\n",
       "13588           naman    9.0       19.0\n",
       "9924             kung    9.0        7.0\n",
       "5365             fuck    9.0        7.0\n",
       "20867            ulol    9.0        0.0\n",
       "9210             kaya    9.0        3.0\n",
       "9254             kayo    8.0        2.0\n",
       "14717             nyo    8.0        5.0\n",
       "14454            niyo    8.0        8.0\n",
       "18038              si    7.0       17.0\n",
       "11697              me    7.0       16.0\n",
       "16798    putangina mo    7.0        0.0\n",
       "8312            ka ba    7.0        1.0\n",
       "15615            pang    6.0        1.0\n",
       "5373         fuck you    6.0        4.0\n",
       "6965            hindi    6.0        9.0"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tokens = vect.get_feature_names()\n",
    "\n",
    "bully_count = nb.feature_count_[0, :].tolist()\n",
    "not_bully_count = nb.feature_count_[1, :].tolist()\n",
    "\n",
    "cols = ['tokens','Bully','Not bully']\n",
    "num = 0\n",
    "data = []\n",
    "while num < len(X_tokens):\n",
    "    data.append([X_tokens[num],bully_count[num],not_bully_count[num]])\n",
    "    num += 1\n",
    "tokens = pd.DataFrame(data=data,columns=cols)\n",
    "tokens.sort_values('Bully', ascending=False)[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping of Bully Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.read_csv('tweets May 23.csv',encoding='ISO-8859-1')\n",
    "\n",
    "new_data = new_data[np.isfinite(new_data['lat'])]\n",
    "\n",
    "X_test_dtm  = vect.transform(new_data['text'])\n",
    "\n",
    "y_predicted = nb.predict(X_test_dtm)\n",
    "\n",
    "lat = new_data.lat.tolist()\n",
    "lon = new_data.lon.tolist()\n",
    "name = new_data.screen_name.tolist()\n",
    "\n",
    "input_text = pd.DataFrame(tweet_text)\n",
    "prediction = pd.DataFrame(y_predicted)\n",
    "name = pd.DataFrame(name)\n",
    "lat = pd.DataFrame(lat)\n",
    "lon = pd.DataFrame(lon)\n",
    "\n",
    "tweet_dots = pd.concat([lat,lon,name,prediction,input_text],axis=1)\n",
    "tweet_dots.columns = ['lat','lon','name','Prediction','text']\n",
    "# table.to_csv('predicted_'+file)\n",
    "# table.sample(n=20)\n",
    "\n",
    "# #tweet_dots = pd.concat([lat_df,lon_df],axis=1)\n",
    "\n",
    "tweet_dots['Prediction']\n",
    "coord = tweet_dots[tweet_dots['Prediction']=='Bully']\n",
    "\n",
    "# # coord\n",
    "# # #map_object = folium.Map(location=[65, -18.6], zoom_start=6, tiles=\"Stamen toner\")\n",
    "map_object = folium.Map(location=[14.5995, 120.9842], zoom_start=12)# 14.5995° N, 120.9842° E Manila\n",
    "\n",
    "# # #marker = folium.features.CircleMarker([(14.5995,120.8889),(14.5980,120.8889),radius=3,color=\"red\",fill_color='red', popup=\"sample tweets\")\n",
    "\n",
    "for lat,lon,name in zip(coord['lat'],coord['lon'],coord['name']):\n",
    "    map_object.add_child(folium.Marker(location=[lat,lon], popup=(folium.Popup(name))))\n",
    "\n",
    "# # # marker = folium.features.Marker(location=[coord['lat'][1],coord['lon'][1]], popup=\"sample tweets\")\n",
    "# # # map_object.add_child(marker)\n",
    "\n",
    "folium.Map.save(map_object, \"index.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
